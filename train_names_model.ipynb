{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c9315ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'df_preprocces.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "256fd44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import re\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade49da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize some char\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37789e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read dataframe\n",
    "df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46e8f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name'] = df['name'].apply(lambda x: normalize_arabic(x)) #apply normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cdb3738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31734, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "166f192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13934</th>\n",
       "      <td>30725</td>\n",
       "      <td>طءهر ساعد ناجده</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>22509</td>\n",
       "      <td>مئمون عاليه نشمي</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26351</th>\n",
       "      <td>12744</td>\n",
       "      <td>ساره جمعان صدام</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12205</th>\n",
       "      <td>26044</td>\n",
       "      <td>نزيه ايثم لوث</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23176</th>\n",
       "      <td>21946</td>\n",
       "      <td>حفصه كذاري انبهاج</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>16643</td>\n",
       "      <td>ديمه منههي هطير</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23397</th>\n",
       "      <td>15312</td>\n",
       "      <td>نصر اغلب زيدان</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27541</th>\n",
       "      <td>17759</td>\n",
       "      <td>وليفه رئيف بطاح</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22376</th>\n",
       "      <td>17867</td>\n",
       "      <td>تيسير برج زكيه</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>26784</td>\n",
       "      <td>مبخلت خطاب المثني</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0               name  status\n",
       "13934       30725    طءهر ساعد ناجده     0.0\n",
       "6169        22509   مئمون عاليه نشمي     0.0\n",
       "26351       12744    ساره جمعان صدام     1.0\n",
       "12205       26044      نزيه ايثم لوث     0.0\n",
       "23176       21946  حفصه كذاري انبهاج     0.0\n",
       "22770       16643    ديمه منههي هطير     0.0\n",
       "23397       15312     نصر اغلب زيدان     1.0\n",
       "27541       17759    وليفه رئيف بطاح     0.0\n",
       "22376       17867     تيسير برج زكيه     0.0\n",
       "2360        26784  مبخلت خطاب المثني     0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19382ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['name'], df['status'], test_size=0.15, random_state=1000) #Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22f3d883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[683, 707, 522]\n",
      "عليان روكن جليل\n"
     ]
    }
   ],
   "source": [
    "#preprocces\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['name'].values)\n",
    "\n",
    "X_train_tok = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tok = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(X_train_tok[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4a13a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20636"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = 3\n",
    "X_train = pad_sequences(X_train_tok, padding='post',maxlen=maxlen,truncating='post')\n",
    "X_test = pad_sequences(X_test_tok, padding='post', maxlen=maxlen,truncating='post')\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "029069c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 3, 32)             660352    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               82432     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 759,489\n",
      "Trainable params: 759,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "\n",
    "embedding_dim = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(LSTM(128, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(.4))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(.5))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    filepath= 'name.h5')\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8626a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "53/53 [==============================] - 11s 75ms/step - loss: 0.6790 - accuracy: 0.5846 - val_loss: 0.5713 - val_accuracy: 0.7807\n",
      "Epoch 2/6\n",
      "53/53 [==============================] - 3s 50ms/step - loss: 0.2897 - accuracy: 0.8892 - val_loss: 0.1708 - val_accuracy: 0.9397\n",
      "Epoch 3/6\n",
      "53/53 [==============================] - 3s 53ms/step - loss: 0.0652 - accuracy: 0.9847 - val_loss: 0.1314 - val_accuracy: 0.9578\n",
      "Epoch 4/6\n",
      "53/53 [==============================] - 3s 51ms/step - loss: 0.0487 - accuracy: 0.9894 - val_loss: 0.1671 - val_accuracy: 0.9471\n",
      "Epoch 5/6\n",
      "53/53 [==============================] - 3s 53ms/step - loss: 0.0438 - accuracy: 0.9906 - val_loss: 0.2283 - val_accuracy: 0.9311\n",
      "Epoch 6/6\n",
      "53/53 [==============================] - 3s 48ms/step - loss: 0.0419 - accuracy: 0.9901 - val_loss: 0.2510 - val_accuracy: 0.9252\n",
      "Training Accuracy: 0.9918066263198853\n",
      "Testing Accuracy:  0.9252257943153381\n"
     ]
    }
   ],
   "source": [
    "# Trainning\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=6,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=512,\n",
    "                    callbacks=[model_checkpoint_callback])\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(f\"Training Accuracy: {accuracy}\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(f\"Testing Accuracy:  {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2211558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the objects:\n",
    "with open('tokenizer.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41edb5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 249ms/step\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 297 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99323195"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Testing\n",
    "name = ['محمد علي السيد']\n",
    "x = tokenizer.texts_to_sequences(normalize_arabic(name[0]).split(\"-*-\"))\n",
    "x = pad_sequences(x, padding='post',maxlen=3,truncating='post')\n",
    "model.predict(x)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6ddc49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"name.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd7d14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
